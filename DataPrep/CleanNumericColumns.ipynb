{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next\n",
    "\n",
    "1. Split up column 40 into 1 or 2 columns: \"TotalCost\" and \"CostPerKg\". However - that would result in effectively two different data sets.\n",
    "2. Convert \"TotalCost\" units into millions/thousands of shillings? Depends what the magnitude is. Otherwise, leave as raw numbers. \n",
    "\n",
    "## Main Income cols to clean\n",
    "\n",
    "1. ~~Q38.CashCropEarnings~~\n",
    "2. ~~Q61.CropEarning~~\n",
    "3. ~~Q69.AmountEarnedCattle~~\n",
    "4. ~~Q72.TotalEarningCattle [note I don't know the difference between Q69 and Q72; some people have given same answers for both, some people haven't...]~~\n",
    "5. ~~Q113.CostOfChange~~\n",
    "6. ~~Q118.CostStarting~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('DataPrep/UgandaClean.csv')\n",
    "df2 = pd.read_csv('DataPrep/KenyaClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.columns[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export unique values\n",
    "\n",
    "target_cols = ['Q21','Q93', 'Q28', 'Q95', 'Q97', 'Q99', 'Q147', 'Q148', 'Q150', 'Q162', 'Q163', 'Q165', 'Q166', 'Q170', 'Q171']\n",
    "\n",
    "\n",
    "find_cols = [col for target in target_cols for col in df.columns if target in col and not '.FreeText' in col and not '.Clean' in col]\n",
    "find_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cols with nothing in them\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def build_dataframe_from_uniques(source_dataframe, cols_to_export, target_file):\n",
    "    uniques_dict = { col: pd.Series(pd.unique(source_dataframe[col].dropna())) for col in cols_to_export }\n",
    "    uniques_df = pd.DataFrame.from_dict(uniques_dict)\n",
    "    uniques_df = uniques_df.replace('-1', np.nan)\n",
    "    uniques_df.to_csv(target_file)\n",
    "    print 'exported to ' + target_file\n",
    "\n",
    "cols_to_export = ['Q21.Income.Other.O6.Text',\n",
    "                  'Q28.FarmHealth.Text',\n",
    "  'Q93.BankAccountChallenges',\n",
    "  'Q97.BankCreditChallenges', \n",
    " 'Q148.IdeasOfChanges', \n",
    " 'Q95.BankLoanFacilityChallenges',\n",
    " 'Q99.SACCOChallenges',\n",
    " 'Q147.OtherInfoAreas',\n",
    " 'Q150.HelpToImplementChanges',\n",
    " 'Q162.MainChallengesOnFarm',\n",
    " 'Q163.SolutionsToAddressProblems',\n",
    "\n",
    " 'Q166.ShareNewFarmingPractice.Example',\n",
    " 'Q170.ChallengesOfSharingInfo',\n",
    " 'Q171.MakeSharingEasier']\n",
    "\n",
    "\n",
    "\n",
    "build_dataframe_from_uniques(df, cols_to_export,'DataPrep/Uganda_UniqueNarrativeDataValues.csv' )\n",
    "build_dataframe_from_uniques(df2, cols_to_export,'DataPrep/Kenya_UniqueNarrativeDataValues.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_df = pd.read_csv('DataPrep/Uganda_UniqueNarrativeDataValues.csv')\n",
    "u_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile(expression):\n",
    "    return re.compile(expression, re.I)\n",
    "\n",
    "def clean_amount_columns (row, column_name):\n",
    "    input_value = row[column_name]\n",
    "     \n",
    "    if pd.isnull(input_value):\n",
    "        return input_value \n",
    "    \n",
    "    # global cleanup\n",
    "    input_value = re.sub('\\s', '', input_value)\n",
    "    leading_string_pattern = compile('v')\n",
    "    input_value = leading_string_pattern.sub('', input_value)\n",
    "    \n",
    "    commas_pattern = compile('^[\\d\\,]+$')\n",
    "    commas_pattern_with_random_end_string = compile('^[\\d\\,]+[^\\d]+$')\n",
    "    m_pattern = compile('^\\d{1,}(\\.\\d{1,})?m(illion|ilion)?(ugx)?')\n",
    "    commas_and_currency_pattern = compile('^[\\d\\,]+(ugx|/=|shs)$')\n",
    "    commas_and_currency_with_random_end_string = compile('^[\\d\\,]+(ugx|/=)[^\\d]+$')\n",
    "    no_numbers_pattern = compile('^[^\\d]+$')\n",
    "    \n",
    "\n",
    "    replace_million = compile('m(illion|ilion)?(ugx)?')\n",
    "    replace_comma = compile('(\\,)')\n",
    "    replace_currency = compile('(ugx|/=|shs)')\n",
    "    replace_currency_with_random_string = compile('(ugx|/=|shs)[^\\d]+')\n",
    "    replace_random_end_string = compile('[^\\d]+$')\n",
    "    \n",
    "    if commas_pattern.search(input_value):\n",
    "        return float(replace_comma.sub('', input_value))\n",
    "    elif m_pattern.search(input_value):\n",
    "        number_only = float(replace_million.sub('', input_value)) * 1000000\n",
    "        return number_only\n",
    "    elif commas_and_currency_pattern.search(input_value):\n",
    "        stripped_of_commas = replace_comma.sub('', input_value)\n",
    "        return float(replace_currency.sub('', stripped_of_commas))\n",
    "    elif commas_and_currency_with_random_end_string.search(input_value):\n",
    "        stripped_of_commas = replace_comma.sub('', input_value)\n",
    "        return float(replace_currency_with_random_string.sub('', stripped_of_commas))\n",
    "    elif commas_pattern_with_random_end_string.search(input_value):\n",
    "        stripped_of_commas = replace_comma.sub('', input_value)\n",
    "        return float(replace_random_end_string.sub('', stripped_of_commas))\n",
    "    elif re.search(no_numbers_pattern, input_value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return input_value\n",
    "    \n",
    "def keep_free_text_only (row, column_name): \n",
    "    input_value = row[column_name]   \n",
    "    if pd.isnull(input_value):\n",
    "        return input_value \n",
    "    no_numbers_pattern = compile('^[^\\d]*$')\n",
    "    if no_numbers_pattern.search(input_value):\n",
    "        return input_value\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def clean_numeric_columns_in(dataframe, cols_to_clean):\n",
    "    for col_name in cols_to_clean:\n",
    "        clean_col_name = col_name+'.Clean'\n",
    "        freetext_col_name = col_name+'.FreeText'\n",
    "        if ~(dataframe[clean_col_name].apply(np.isreal).all(skipna=True)):\n",
    "            print('cleaning ' + col_name)\n",
    "            dataframe[freetext_col_name] = dataframe.apply(lambda row:keep_free_text_only(row, col_name), axis=1)\n",
    "            dataframe[clean_col_name] = dataframe.apply(lambda row: clean_amount_columns(row, col_name), axis=1)\n",
    "        else:\n",
    "            print('skipping, already clean: ' + col_name)\n",
    "        print(col_name, dataframe[clean_col_name].apply(np.isreal).all(skipna=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_df = df2\n",
    "\n",
    "# Q38, Q61, Q69, Q72, Q113, Q118\n",
    "target_cols = ['Q38', 'Q61', 'Q69', 'Q72', 'Q113', 'Q118']\n",
    "\n",
    "cols_to_clean = [col for target in target_cols for col in target_df.columns if target in col and not '.FreeText' in col and not '.Clean' in col]\n",
    "\n",
    "print(cols_to_clean)\n",
    "\n",
    "\n",
    "clean_numeric_columns_in(df, cols_to_clean)\n",
    "\n",
    "[col for target in target_cols for col in target_df.columns if target in col]\n",
    "#pd.unique(df[cols_to_clean[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use for investigating false columns\n",
    "\n",
    "pd.unique(df2['Q69.AmountEarnedCattle'])\n",
    "df2['Q69.AmountEarnedCattle']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv('DataPrep/UgandaClean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
